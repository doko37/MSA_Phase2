{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "## Author - Peter Lee\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This report will present a NN model trained to classify the CIFAR-10 dataset.\n",
    "\n",
    "The label I have chosen for object detection is Ship which is label 8.\n",
    "I have chosen this label as ships are always on water, which is a distinct difference compared to the other classes (although there is some overlap with planes).\n",
    "I was hoping that the blue in the water would be captured as a pattern for ships in the model.\n",
    "\n",
    "## Modelling Process\n",
    "\n",
    "The dataset contains 60000 images, but for this report I used 10000 images for training and 2000 images for training.\n",
    "\n",
    "The shape of the model is as follows:\n",
    "1 input layer with 3072 input neurons (32 x 32 x 3),\n",
    "4 hidden layers with 255 neurons,\n",
    "and 1 output layer with 10 outputs presenting each class in the dataset.\n",
    "\n",
    "The loss function I chose was sparse categorical cross entropy. This loss function is identical to the categorical cross entropy except it allows the labels to be regular integers (instead of being one hot encoded).\n",
    "The reason I chose this was because my model was having problems with the one hot encoded labels.\n",
    "\n",
    "The optimizer I chose was Adam which is an adaptive optimizer, meaning the learning is adjusting automatically. The reason I chose Adam is because it is widely regarded as the best adaptive opotimizer and usually gives good results. I also tried using SGD (another adaptive optimizer), however the results were not as good compared to Adam.\n",
    "\n",
    "I used GridSearchCV to tune the hyperparameters specifically number of batchs and epochs, which turned out to be 750 batches, with 125 epochs.\n",
    "I also used Stratified Sampling to randomly distribute the training data into different sets to train the model using those new sets. The best test accuracy I could achieve with this method was 48%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "Accuracy:\n",
    "![Accuracy](./images/acc.PNG)\n",
    "\n",
    "Loss:\n",
    "![Loss](./images/loss.PNG)\n",
    "\n",
    "Validation Accuracy:\n",
    "![Val_Acc](./images/val_acc.PNG)\n",
    "\n",
    "Validation Loss:\n",
    "![Val_Loss](./images/val_loss.PNG)\n",
    "\n",
    "The best training accuracy was around 50% while the best test accuracy I could achieve was around 45% which is not great.\n",
    "I struggled with the model overfitting, as I was able to get the training accuracy very high, but the test accuracy would still remain low.\n",
    "I tried to balance the training so the model would not overfit while trying to increase the test accuracy as much as I could.\n",
    "I tried tuning the hyperparameters using grid search and also tried increasing the accuracy by stratifed sampling but those methods only improves the model by a small amount.\n",
    "The shape of the model was also probably not optimal. I assumed that more neurons and hidden layers would result in better performance, however after lots of testing and trial and error, I found that increasing the number of neurons and hidden layers would decrease the accuracy at the certain point.\n",
    "\n",
    "However when it came to evaluating the ship class, the model was quite accurate at around 75%.\n",
    "We can see this on the graph, once the model was evaluated with the filtered test batch which only contained images of the ship class, the acc suddenly jumps up while the loss dips significantly.\n",
    "\n",
    "![Filtered_acc](./images/acc_filtered.PNG)\n",
    "\n",
    "![Filtered.loss](./images/loss_filtered.PNG)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The model was able to correctly classify between the 10 classes around 45% of the time. With a dataset only containing the ship class, the model was much better at correctly classifying those with an accuracy of around 75%.\n",
    "Although I am not happy with the overall performance of the model, I feel like I have learnt a lot through this project. I could have improved in many aspects such as better data cleaning and more exhaustive hyperparameter tuning, things I could have done if I had more time and knowledge before this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f1f59101e07bffb7c2ecfaca1a3c7ffe3cd326ee75e914ab1b038684b38c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
